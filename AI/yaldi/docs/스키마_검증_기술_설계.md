# 스키마 검증 기술 설계

## 목차
1. [스키마 검증이란?](#1-스키마-검증이란)
2. [왜 실제 DB 빌드가 필요한가?](#2-왜-실제-db-빌드가-필요한가)
3. [검증 프로세스](#3-검증-프로세스)
4. [에러 분석 및 수정 제안](#4-에러-분석-및-수정-제안)
5. [검증 흐름](#5-검증-흐름)
6. [설계 결정](#6-설계-결정)

---

## 1. 스키마 검증이란?

### 1.1 스키마 검증의 정의

**스키마 검증 = ERD 설계가 실제로 빌드 가능한지 확인**

- 사용자가 작성한 ERD를 **SQL DDL로 변환**
- **실제 데이터베이스에서 실행** (CREATE TABLE)
- 성공/실패 판정 및 **에러 분석**

**예시:**
```
[사용자 ERD 작성]
- users 테이블 (PK: id)
- orders 테이블 (FK: user_id → users.id)

↓ SQL 변환
CREATE TABLE users (id BIGINT PRIMARY KEY);
CREATE TABLE orders (user_id BIGINT REFERENCES users(id));

↓ 실제 DB 실행
✅ BUILD 성공!
```

### 1.2 왜 필요한가?

**문제: ERD 도구는 문법을 검증하지 않음**

```
사용자가 ERD에서:
- users 테이블의 PK를 설정하지 않음
- orders 테이블에서 users를 참조하는 FK 설정

↓ ERD는 에러를 표시하지 않음 (도구는 몰라요!)

↓ 실제 SQL 변환 후 실행하면?
❌ ERROR: foreign key constraint
→ users 테이블에 PK가 없어서 참조 불가!
```

**스키마 검증의 역할:**
- ✅ 실제 DB에서 빌드 테스트
- ✅ 에러 발견 즉시 알림
- ✅ AI가 에러 분석 + 수정 방법 제안

### 1.3 YALDI의 스키마 검증

**검증 시점:**
- 사용자가 **버전을 저장할 때** 자동 실행 (Kafka 비동기)

**검증 프로세스:**
1. SchemaData → SQL DDL 변환
2. DB 타입 자동 감지 (PostgreSQL/MySQL)
3. 테스트 DB에서 실제 CREATE TABLE 실행
4. 성공: ✅ SUCCESS 상태 저장
5. 실패: ❌ LLM이 에러 분석 → 수정 제안

**사용자 경험:**
```
[저장 버튼 클릭]
    ↓ 즉시 응답 (비동기 처리)
[프론트엔드] "저장 중..."
    ↓ (백그라운드에서 검증)
[알림] ✅ "검증 성공!" 또는 ❌ "에러 발견: [상세 설명]"
```

---

## 2. 왜 실제 DB 빌드가 필요한가?

### 2.1 정적 검증의 한계

**1. 정규식 검증**

```python
# 간단한 정규식 검증
if "CREATE TABLE" in sql and "PRIMARY KEY" in sql:
    return "OK"
```

**문제점:**
- ❌ 문법 오류 감지 못함 (`,` 빠짐, 괄호 불일치)
- ❌ 제약조건 충돌 감지 못함 (PK 없는데 FK 참조)
- ❌ 데이터 타입 호환성 검증 못함

**2. AST(Abstract Syntax Tree) 파싱**

```python
# SQL 파서로 구문 분석
parsed = sqlparse.parse(sql)
if parsed.errors:
    return "ERROR"
```

**문제점:**
- ❌ 복잡한 제약조건 검증 어려움
- ❌ DB별 문법 차이 처리 복잡
- ❌ 실제 실행 환경과 다를 수 있음

### 2.2 실제 DB 빌드의 장점

**모든 오류를 실제 DB가 감지**

```sql
-- 예시 1: 컬럼명 오류
CREATE TABLE users (
    id BIGINT PRIMARY KEY,
    name VARCHAR(100),
    age INTEGER
    email VARCHAR(255)  -- ❌ 쉼표 누락!
);

→ PostgreSQL 에러: syntax error at or near "email"
```

```sql
-- 예시 2: FK 참조 오류
CREATE TABLE orders (
    id BIGINT PRIMARY KEY,
    user_id BIGINT REFERENCES users(id)  -- ❌ users 테이블 없음!
);

→ PostgreSQL 에러: relation "users" does not exist
```

```sql
-- 예시 3: 제약조건 충돌
CREATE TABLE users (
    id BIGINT,  -- ❌ PK 없음
    email VARCHAR(255) UNIQUE
);

CREATE TABLE orders (
    order_id BIGINT PRIMARY KEY,
    user_id BIGINT REFERENCES users(id)  -- ❌ users에 PK 없어서 참조 불가!
);

→ PostgreSQL 에러: there is no unique constraint matching given keys for referenced table "users"
```

**실제 DB 빌드의 이점:**

| 항목 | 정적 검증 | **실제 DB 빌드** |
|------|----------|-----------------|
| 문법 오류 | ⚠️ 부분 | ✅ **완벽** |
| 제약조건 충돌 | ❌ 어려움 | ✅ **자동 감지** |
| FK 참조 무결성 | ❌ 불가 | ✅ **자동 감지** |
| 데이터 타입 호환 | ❌ 불가 | ✅ **자동 감지** |
| DB별 문법 차이 | ❌ 수동 | ✅ **DB가 판단** |

### 2.3 Docker 테스트 DB 사용

**왜 운영 DB가 아닌 테스트 DB인가?**

**운영 DB 사용 시 문제:**
- ❌ 검증 실패 시 DB 상태 오염
- ❌ 동시 검증 시 충돌
- ❌ 보안 위험 (검증용으로 운영 DB 접근)

**Docker 테스트 DB 사용:**
- ✅ **격리된 환경**: 임시 스키마/DB 생성 → 검증 → 삭제
- ✅ **병렬 처리**: 여러 검증 동시 실행 가능
- ✅ **빠른 초기화**: 컨테이너 재시작으로 깨끗한 상태
- ✅ **안전**: 실패해도 운영 DB에 영향 없음

---

## 3. 검증 프로세스

### 3.1 전체 검증 흐름

```
1. SchemaData → SQL 변환
   ↓
2. DB 타입 자동 감지 (PostgreSQL/MySQL)
   ↓
3. 임시 스키마/DB 생성
   ↓
4. CREATE TABLE 실행
   ↓
5. 성공/실패 판정
   ↓ 실패 시
6. LLM 에러 분석 + 수정 제안
```

### 3.2 Step 1: SchemaData → SQL 변환

**SchemaData (JSON 형식):**

```json
{
  "tables": [
    {
      "tableKey": 1,
      "physicalName": "users",
      "logicalName": "사용자",
      "columns": [
        {
          "physicalName": "id",
          "dataType": "BIGINT",
          "isPrimaryKey": true,
          "isNullable": false,
          "isIncremental": true
        },
        {
          "physicalName": "email",
          "dataType": "VARCHAR",
          "dataDetail": ["255"],
          "isUnique": true,
          "isNullable": false
        }
      ]
    },
    {
      "tableKey": 2,
      "physicalName": "orders",
      "columns": [
        {
          "physicalName": "id",
          "dataType": "BIGINT",
          "isPrimaryKey": true
        },
        {
          "physicalName": "user_id",
          "dataType": "BIGINT",
          "isForeignKey": true
        }
      ]
    }
  ],
  "relations": [
    {
      "fromTableKey": 2,
      "toTableKey": 1,
      "constraintName": "fk_orders_users"
    }
  ]
}
```

**SQL 변환 결과:**

```sql
CREATE TABLE users (
    id BIGINT NOT NULL AUTO_INCREMENT,
    email VARCHAR(255) NOT NULL UNIQUE,
    PRIMARY KEY (id)
);

CREATE TABLE orders (
    id BIGINT PRIMARY KEY,
    user_id BIGINT
);

ALTER TABLE orders
ADD CONSTRAINT fk_orders_users
FOREIGN KEY (user_id)
REFERENCES users (id);
```

**변환 로직:**

```python
# schema_converter.py
class SchemaToSQLConverter:
    def convert_to_sql(self, schema_data: SchemaData) -> str:
        sql_statements = []

        # 1. 테이블별 CREATE TABLE 생성
        for table in schema_data.tables:
            create_table_sql = self._generate_create_table(table)
            sql_statements.append(create_table_sql)

        # 2. 외래키 제약조건 (ALTER TABLE)
        for relation in schema_data.relations:
            alter_sql = self._generate_foreign_key(relation, ...)
            sql_statements.append(alter_sql)

        return "\n\n".join(sql_statements)

    def _generate_column_definition(self, column: ColumnSchema) -> str:
        parts = [column.physicalName]

        # 데이터 타입
        data_type = self._format_data_type(column.dataType, column.dataDetail)
        parts.append(data_type)

        # 제약조건
        if not column.isNullable:
            parts.append("NOT NULL")
        if column.isUnique:
            parts.append("UNIQUE")
        if column.isIncremental:
            parts.append("AUTO_INCREMENT")

        return " ".join(parts)
```

### 3.3 Step 2: DB 타입 자동 감지

**문제: PostgreSQL과 MySQL 문법 차이**

| 기능 | PostgreSQL | MySQL |
|------|-----------|-------|
| AUTO_INCREMENT | SERIAL, BIGSERIAL | AUTO_INCREMENT |
| BOOLEAN | BOOLEAN | TINYINT(1) |
| TEXT | TEXT | TEXT |
| ENUM | 미지원 (TEXT 사용) | ENUM('A', 'B') |

**자동 감지 방식 (LLM 활용):**

```python
# version_verification_service.py
async def _detect_db_type(self, sql_content: str) -> str:
    """LLM이 SQL을 보고 DB 타입 판단"""

    prompt = f"""다음 SQL을 분석하여 PostgreSQL인지 MySQL인지 판단하세요.

SQL:
{sql_content}

판단 기준:
- PostgreSQL: SERIAL, BIGSERIAL, BOOLEAN
- MySQL: AUTO_INCREMENT, TINYINT, ENUM

JSON 응답: {{"dbType": "postgresql" or "mysql"}}
"""

    response = await openai_client.json_completion(
        messages=[...],
        temperature=0.0  # 결정론적
    )

    db_type = response.get("dbType", "postgresql")
    return db_type
```

**감지 예시:**

```sql
-- PostgreSQL로 감지
CREATE TABLE users (
    id BIGSERIAL PRIMARY KEY,
    is_active BOOLEAN
);

-- MySQL로 감지
CREATE TABLE users (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    status ENUM('ACTIVE', 'INACTIVE')
);
```

### 3.4 Step 3~5: 실제 DB 빌드 검증

**PostgreSQL 검증:**

```python
# sql_validator.py
async def _validate_postgres(self, sql_content: str) -> Tuple[bool, Optional[str]]:
    """PostgreSQL에서 SQL 검증"""
    schema_name = f"temp_validation_{uuid.uuid4().hex[:8]}"
    conn = None

    try:
        # 1. PostgreSQL 연결
        conn = await asyncpg.connect(TEST_POSTGRES_URL)

        # 2. 임시 스키마 생성
        await conn.execute(f"CREATE SCHEMA {schema_name}")
        await conn.execute(f"SET search_path TO {schema_name}")

        # 3. SQL 파싱 및 실행
        statements = sqlparse.split(sql_content)
        for statement in statements:
            if statement.strip():
                await conn.execute(statement)

        # 4. 성공!
        logger.info("✅ SQL 검증 성공")
        return True, None

    except Exception as e:
        # 5. 실패 - 에러 메시지 반환
        error_msg = str(e)
        logger.error(f"❌ SQL 검증 실패: {error_msg}")
        return False, error_msg

    finally:
        # 6. 임시 스키마 삭제 (정리)
        await conn.execute(f"DROP SCHEMA IF EXISTS {schema_name} CASCADE")
        await conn.close()
```

**검증 성공 예시:**

```
[INFO] Connected to PostgreSQL, creating schema: temp_validation_a3f8b2c1
[DEBUG] Executing: CREATE TABLE users (id BIGINT PRIMARY KEY, ...)
[DEBUG] Executing: CREATE TABLE orders (id BIGINT, user_id BIGINT, ...)
[DEBUG] Executing: ALTER TABLE orders ADD CONSTRAINT fk_orders_users ...
[INFO] ✅ SQL 검증 성공
[INFO] Cleaned up schema: temp_validation_a3f8b2c1
```

**검증 실패 예시:**

```
[INFO] Connected to PostgreSQL, creating schema: temp_validation_d7e9a1f4
[DEBUG] Executing: CREATE TABLE users (id BIGINT, ...)
[DEBUG] Executing: CREATE TABLE orders (user_id BIGINT REFERENCES users(id), ...)
[ERROR] ❌ SQL 검증 실패: there is no unique constraint matching given keys for referenced table "users"
[INFO] Cleaned up schema: temp_validation_d7e9a1f4
```

---

## 4. 에러 분석 및 수정 제안

### 4.1 LLM 에러 분석

**검증 실패 시 LLM이 분석:**

```python
# version_verification_service.py
async def _analyze_error_with_llm(
    self,
    sql_content: str,
    error_message: str,
    db_type: str
) -> dict:
    """LLM을 사용하여 에러 분석 및 수정 제안"""

    prompt = f"""다음 SQL DDL에서 빌드 에러가 발생했습니다. 에러를 분석하고 수정 방법을 제안하세요.

데이터베이스: {db_type.upper()}

SQL:
```sql
{sql_content}
```

에러 메시지:
```
{error_message}
```

다음 형식의 JSON으로 응답하세요:
{{
    "errors": ["구체적인 에러 설명1", "구체적인 에러 설명2"],
    "warnings": ["경고사항1", "경고사항2"],
    "message": "사용자 친화적인 전체 요약 메시지",
    "suggestions": ["구체적인 수정 방법1", "구체적인 수정 방법2"]
}}

요구사항:
- errors: 발생한 에러들을 사용자가 이해하기 쉽게 설명
- warnings: 에러는 아니지만 주의할 점
- message: 전체 상황을 요약한 친절한 메시지
- suggestions: 구체적이고 실행 가능한 수정 방법 제시
"""

    response = await openai_client.json_completion(
        messages=[
            {
                "role": "system",
                "content": "당신은 데이터베이스 전문가입니다. SQL 에러를 분석하고 초보자도 이해할 수 있도록 친절하게 설명합니다."
            },
            {
                "role": "user",
                "content": prompt
            }
        ],
        temperature=0.3,  # 안정적인 분석
        max_tokens=1000
    )

    return {
        "errors": response.get("errors", [error_message]),
        "warnings": response.get("warnings"),
        "message": response.get("message", "SQL 빌드에 실패했습니다."),
        "suggestions": response.get("suggestions", ["스키마를 확인하고 다시 시도해주세요."])
    }
```

### 4.2 실제 에러 분석 예시

#### 예시 1: PRIMARY KEY 누락

**SQL:**
```sql
CREATE TABLE users (
    id BIGINT,
    email VARCHAR(255)
);

CREATE TABLE orders (
    id BIGINT PRIMARY KEY,
    user_id BIGINT REFERENCES users(id)
);
```

**DB 에러:**
```
there is no unique constraint matching given keys for referenced table "users"
```

**LLM 분석 결과:**

```json
{
  "errors": [
    "users 테이블에 PRIMARY KEY가 설정되어 있지 않습니다.",
    "orders 테이블에서 users.id를 참조하려고 하지만, users.id가 UNIQUE 제약조건이 없어 참조할 수 없습니다."
  ],
  "warnings": [
    "외래키는 반드시 부모 테이블의 PRIMARY KEY 또는 UNIQUE 컬럼을 참조해야 합니다."
  ],
  "message": "users 테이블에 PRIMARY KEY가 없어서 orders 테이블에서 외래키로 참조할 수 없습니다. users 테이블의 id 컬럼에 PRIMARY KEY 제약조건을 추가해주세요.",
  "suggestions": [
    "users 테이블의 id 컬럼을 PRIMARY KEY로 설정하세요.",
    "ERD에서 users 테이블의 id 컬럼에 PK 체크박스를 활성화하세요.",
    "또는 users 테이블의 id 컬럼에 UNIQUE 제약조건을 추가하세요."
  ]
}
```

**사용자에게 표시:**

```
❌ 스키마 검증 실패

문제:
- users 테이블에 PRIMARY KEY가 설정되어 있지 않습니다.
- orders 테이블에서 users.id를 참조하려고 하지만, users.id가 UNIQUE 제약조건이 없어 참조할 수 없습니다.

경고:
- 외래키는 반드시 부모 테이블의 PRIMARY KEY 또는 UNIQUE 컬럼을 참조해야 합니다.

수정 방법:
1. users 테이블의 id 컬럼을 PRIMARY KEY로 설정하세요.
2. ERD에서 users 테이블의 id 컬럼에 PK 체크박스를 활성화하세요.
3. 또는 users 테이블의 id 컬럼에 UNIQUE 제약조건을 추가하세요.
```

#### 예시 2: 컬럼 중복

**SQL:**
```sql
CREATE TABLE users (
    id BIGINT PRIMARY KEY,
    email VARCHAR(255),
    email VARCHAR(100)  -- 중복!
);
```

**DB 에러:**
```
column "email" specified more than once
```

**LLM 분석 결과:**

```json
{
  "errors": [
    "users 테이블에 email 컬럼이 중복으로 정의되어 있습니다."
  ],
  "warnings": [
    "테이블 내에서 컬럼명은 고유해야 합니다."
  ],
  "message": "users 테이블에 email 컬럼이 2번 정의되어 있습니다. 중복된 컬럼을 제거하거나 다른 이름으로 변경하세요.",
  "suggestions": [
    "ERD에서 users 테이블의 중복된 email 컬럼을 삭제하세요.",
    "두 컬럼이 다른 용도라면 이름을 구분해주세요 (예: email, personal_email)."
  ]
}
```

#### 예시 3: 외래키 순서 오류

**SQL:**
```sql
CREATE TABLE orders (
    id BIGINT PRIMARY KEY,
    user_id BIGINT REFERENCES users(id)  -- users가 아직 없음!
);

CREATE TABLE users (
    id BIGINT PRIMARY KEY
);
```

**DB 에러:**
```
relation "users" does not exist
```

**LLM 분석 결과:**

```json
{
  "errors": [
    "orders 테이블에서 users 테이블을 참조하려고 하지만, users 테이블이 아직 생성되지 않았습니다."
  ],
  "warnings": [
    "외래키를 설정할 때는 참조되는 테이블(부모 테이블)이 먼저 생성되어 있어야 합니다."
  ],
  "message": "테이블 생성 순서가 잘못되었습니다. users 테이블을 먼저 생성한 후 orders 테이블을 생성해야 합니다.",
  "suggestions": [
    "ERD에서 테이블 순서를 조정할 필요는 없습니다. 외래키 제약조건은 ALTER TABLE로 나중에 추가됩니다.",
    "만약 문제가 계속되면 외래키 관계를 다시 설정해보세요."
  ]
}
```

#### 예시 4: 데이터 타입 불일치

**SQL:**
```sql
CREATE TABLE users (
    id VARCHAR(50) PRIMARY KEY
);

CREATE TABLE orders (
    id BIGINT PRIMARY KEY,
    user_id BIGINT REFERENCES users(id)  -- VARCHAR와 BIGINT 불일치!
);
```

**DB 에러:**
```
foreign key constraint "fk_orders_users" cannot be implemented
DETAIL: Key columns "user_id" and "id" are of incompatible types: bigint and character varying
```

**LLM 분석 결과:**

```json
{
  "errors": [
    "orders 테이블의 user_id 컬럼(BIGINT)과 users 테이블의 id 컬럼(VARCHAR)의 데이터 타입이 일치하지 않습니다."
  ],
  "warnings": [
    "외래키는 참조하는 컬럼과 참조되는 컬럼의 데이터 타입이 동일해야 합니다."
  ],
  "message": "외래키 관계에서 데이터 타입이 일치하지 않습니다. users.id는 VARCHAR이지만 orders.user_id는 BIGINT입니다.",
  "suggestions": [
    "users 테이블의 id 컬럼을 BIGINT로 변경하세요.",
    "또는 orders 테이블의 user_id 컬럼을 VARCHAR(50)으로 변경하세요.",
    "일반적으로 ID는 BIGINT를 권장합니다."
  ]
}
```

---

## 5. 검증 흐름

### 5.1 전체 아키텍처

```
[User] 버전 저장
    ↓
[Backend] POST /api/v1/versions
    ↓ Version DB 저장
[Backend] Kafka 메시지 발행 → yaldi.version.verification
    ↓
[Kafka Consumer] VersionProcessingConsumerListener
    ↓
[AI Server] POST /api/v1/version/verification
    ↓
1. SchemaData → SQL 변환
    ↓
2. DB 타입 자동 감지 (LLM)
    ↓
3. Docker Test DB 빌드 검증
    ↓ 성공?
[성공] ✅ SUCCESS 상태 저장
    ↓
[실패] ❌ LLM 에러 분석 → FAILED 상태 + 수정 제안 저장
    ↓
[Frontend] SSE로 실시간 결과 알림
```

### 5.2 상세 단계별 흐름

#### Step 1: Kafka Consumer 수신

```java
// VersionProcessingConsumerListener.java
@KafkaListener(topics = "yaldi.version.verification")
public void consumeVersionVerificationRequest(VersionProcessingMessage message) {
    log.info("버전 검증 요청 수신 - VersionKey: {}", message.versionKey());

    Version version = versionRepository.findById(message.versionKey())
        .orElseThrow(...);

    // 검증 상태: RUNNING
    version.updateVerificationStatus(DesignVerificationStatus.RUNNING);
    versionRepository.save(version);

    try {
        // AI 서버에 검증 요청
        VersionVerificationResult result = aiClient.verifySchema(
            message.schemaData(),
            message.versionName()
        );

        // 검증 결과 저장
        version.updateVerificationStatus(result.status());

        Map<String, Object> verificationResultMap = new HashMap<>();
        verificationResultMap.put("errors", result.errors());
        verificationResultMap.put("warnings", result.warnings());
        verificationResultMap.put("message", result.message());
        verificationResultMap.put("suggestions", result.suggestions());
        version.updateVerificationResult(verificationResultMap);

        versionRepository.save(version);

        log.info("스키마 검증 완료 - Status: {}", result.status());

    } catch (Exception e) {
        log.error("스키마 검증 실패", e);
        version.updateVerificationStatus(DesignVerificationStatus.FAILED);
        versionRepository.save(version);
    }
}
```

#### Step 2: AI Server - 검증 수행

```python
# version_verification_service.py
async def verify_version(self, request: VersionVerificationRequest):
    """버전 스키마 검증"""

    # 1. SchemaData → SQL 변환
    sql_content = schema_converter.convert_to_sql(request.schema_data)

    # 2. DB 타입 자동 감지
    db_type = await self._detect_db_type(sql_content)
    # 결과: "postgresql" or "mysql"

    # 3. SQL 빌드 검증
    success, error_message = await sql_validator.validate_sql(
        sql_content=sql_content,
        db_type=db_type
    )

    # 4-A. 성공
    if success:
        return VersionVerificationResponse(
            is_valid=True,
            status="SUCCESS",
            message="스키마 검증이 완료되었습니다. 문제가 없습니다."
        )

    # 4-B. 실패 - LLM 분석
    analysis = await self._analyze_error_with_llm(
        sql_content=sql_content,
        error_message=error_message,
        db_type=db_type
    )

    return VersionVerificationResponse(
        is_valid=False,
        status="FAILED",
        errors=analysis["errors"],
        warnings=analysis.get("warnings"),
        message=analysis["message"],
        suggestions=analysis["suggestions"]
    )
```

#### Step 3: 검증 결과 저장

**PostgreSQL (versions 테이블):**

```sql
-- 성공 시
UPDATE versions
SET design_verification_status = 'SUCCESS',
    verification_result = '{
      "message": "스키마 검증이 완료되었습니다. 문제가 없습니다."
    }'::jsonb
WHERE id = 123;

-- 실패 시
UPDATE versions
SET design_verification_status = 'FAILED',
    verification_result = '{
      "errors": ["users 테이블에 PRIMARY KEY가 없습니다."],
      "warnings": ["외래키는 부모 테이블의 PK를 참조해야 합니다."],
      "message": "users 테이블에 PK가 없어서 orders에서 참조할 수 없습니다.",
      "suggestions": ["users.id를 PRIMARY KEY로 설정하세요."]
    }'::jsonb
WHERE id = 123;
```

#### Step 4: Frontend 표시

**성공 화면:**
```
✅ 검증 성공

스키마 검증이 완료되었습니다. 문제가 없습니다.
```

**실패 화면:**
```
❌ 검증 실패

문제:
• users 테이블에 PRIMARY KEY가 설정되어 있지 않습니다.
• orders 테이블에서 users.id를 참조하려고 하지만 참조할 수 없습니다.

경고:
• 외래키는 반드시 부모 테이블의 PRIMARY KEY를 참조해야 합니다.

수정 방법:
1. users 테이블의 id 컬럼을 PRIMARY KEY로 설정하세요.
2. ERD에서 users 테이블의 id 컬럼에 PK 체크박스를 활성화하세요.
```

---

## 6. 설계 결정

### 6.1 왜 Kafka 비동기 처리인가?

**동기 처리 시 문제:**
```
[User] 저장 버튼 클릭
    ↓ (대기 시작)
[Backend] SQL 변환 (1초)
    ↓
[Backend] DB 검증 (3초)
    ↓
[Backend] LLM 분석 (5초, 실패 시)
    ↓ (최대 9초 후)
[User] 응답 받음 (너무 느림!)
```

**Kafka 비동기 처리:**
```
[User] 저장 버튼 클릭
    ↓
[Backend] DB 저장 (0.1초)
    ↓ 즉시 응답
[User] "저장 완료, 검증 중..."
    ↓ (백그라운드에서 검증)
[Kafka Consumer] SQL 변환 + 검증 + 분석 (최대 9초)
    ↓
[Frontend SSE] "검증 완료!" 알림
```

**효과:**
- 사용자 대기 시간: 9초 → **0.1초**
- UX 향상 (즉시 응답)
- 서버 부하 분산

### 6.2 임시 스키마/DB 격리

**왜 임시 공간을 만드나?**

```python
# PostgreSQL
schema_name = f"temp_validation_{uuid.uuid4().hex[:8]}"  # temp_validation_a3f8b2c1

# MySQL
db_name = f"temp_validation_{uuid.uuid4().hex[:8]}"  # temp_validation_d7e9a1f4
```

**이유:**

| 문제 | 임시 스키마/DB 솔루션 |
|------|---------------------|
| 동시 검증 시 충돌 | ✅ UUID로 고유 이름 생성 → 격리 |
| 검증 실패 시 DB 오염 | ✅ 임시 공간이므로 영향 없음 |
| 정리 누락 시 쓰레기 데이터 | ✅ finally 블록에서 반드시 삭제 |
| 병렬 처리 불가 | ✅ 격리되어 있어 병렬 가능 |

**정리 코드:**
```python
finally:
    # 성공/실패 무관하게 반드시 정리
    await conn.execute(f"DROP SCHEMA IF EXISTS {schema_name} CASCADE")
```

### 6.3 PostgreSQL + MySQL 둘 다 지원

**왜 두 DB 모두 검증?**

- 사용자가 PostgreSQL 문법으로 작성 → PostgreSQL 검증
- 사용자가 MySQL 문법으로 작성 → MySQL 검증

**자동 감지의 이점:**
- ✅ 사용자가 DB 타입 선택 불필요
- ✅ LLM이 SQL을 보고 자동 판단
- ✅ 정확한 DB로 검증 (문법 차이 대응)

### 6.4 LLM temperature=0.3 (에러 분석)

**왜 0.3인가?**

```python
# 에러 분석: temperature=0.3
response = await openai_client.json_completion(
    messages=[...],
    temperature=0.3  # 안정적이면서도 친절한 설명
)
```

**temperature 비교:**

| 값 | 특성 | 에러 분석에서 |
|----|------|--------------|
| 0.0 | 결정론적, 항상 같은 응답 | ❌ 설명이 기계적 |
| **0.3** | 안정적 + 약간의 변화 | ✅ **친절하고 명확** |
| 0.7 | 창의적, 다양한 표현 | ❌ 불필요한 변형 |
| 1.0 | 매우 창의적 | ❌ 일관성 없음 |

**0.3의 효과:**
- 에러 메시지를 사용자 친화적으로 설명
- 구체적이고 실행 가능한 제안
- 일관성 유지 (같은 에러는 비슷한 설명)

### 6.5 검증은 항상 수행 (Graph RAG는 SUCCESS만)

**왜 검증 실패해도 검증 자체는 항상 하나?**

```java
// 1. 스키마 검증 (항상 수행)
result = aiClient.verifySchema(...);
version.updateVerificationStatus(result.status());

// 2. Graph RAG 인덱싱 (SUCCESS일 때만)
if (verificationSuccess && status == SUCCESS) {
    graphRagAiClient.indexToGraph(...);
}
```

**이유:**

| 기능 | 검증 FAILED 시 동작 | 이유 |
|------|-------------------|------|
| **스키마 검증** | ✅ 항상 수행 | 사용자에게 에러 알려야 함 |
| **Graph RAG** | ❌ 수행 안 함 | 잘못된 패턴 학습 방지 |
| **임베딩** | ✅ 항상 수행 | 검색 가능해야 함 (실패해도 찾을 수 있어야) |

### 6.6 sqlparse로 SQL 파싱

**왜 sqlparse를 사용하나?**

```python
# SQL을 개별 문장으로 분리
statements = sqlparse.split(sql_content)

for statement in statements:
    if statement.strip():
        await conn.execute(statement)
```

**이유:**
- SQL 파일에는 여러 CREATE TABLE, ALTER TABLE 문이 있음
- 세미콜론(`;`)으로 구분하지만 문자열 안에도 `;`가 있을 수 있음
- **sqlparse가 정확하게 파싱**

**예시:**
```sql
CREATE TABLE users (
    bio TEXT DEFAULT 'Hello; World'  -- 문자열 안 세미콜론
);  -- 실제 종료

CREATE TABLE orders (...);
```

→ sqlparse는 문자열 안 `;`를 무시하고 정확히 2개 문장으로 분리

---

## 7. 실제 사례

### 예시: "전자상거래 시스템" 스키마 검증

**사용자 ERD (실수로 PK 누락):**

```
테이블: products
- id (BIGINT) ← PK 체크 안 함 (실수!)
- name (VARCHAR(200))
- price (DECIMAL(10,2))

테이블: orders
- id (BIGINT, PK)
- product_id (BIGINT, FK → products.id)
- quantity (INTEGER)
```

**SQL 변환 결과:**

```sql
CREATE TABLE products (
    id BIGINT,
    name VARCHAR(200),
    price DECIMAL(10,2)
);

CREATE TABLE orders (
    id BIGINT PRIMARY KEY,
    product_id BIGINT,
    quantity INTEGER
);

ALTER TABLE orders
ADD CONSTRAINT fk_orders_products
FOREIGN KEY (product_id)
REFERENCES products (id);
```

**검증 실패:**

```
❌ PostgreSQL 에러:
there is no unique constraint matching given keys for referenced table "products"
```

**LLM 에러 분석:**

```json
{
  "errors": [
    "products 테이블에 PRIMARY KEY가 설정되어 있지 않습니다.",
    "orders 테이블에서 products.id를 외래키로 참조하려고 하지만, products.id에 UNIQUE 제약조건이 없어 참조할 수 없습니다."
  ],
  "warnings": [
    "외래키는 반드시 부모 테이블의 PRIMARY KEY 또는 UNIQUE 컬럼을 참조해야 합니다.",
    "모든 테이블에는 PRIMARY KEY를 설정하는 것이 좋습니다."
  ],
  "message": "products 테이블에 PRIMARY KEY가 없어서 orders 테이블에서 외래키로 참조할 수 없습니다. products 테이블의 id 컬럼에 PRIMARY KEY 제약조건을 추가해주세요.",
  "suggestions": [
    "ERD에서 products 테이블의 id 컬럼에 PK(Primary Key) 체크박스를 활성화하세요.",
    "products.id를 PRIMARY KEY로 설정하면 자동으로 UNIQUE 제약조건이 적용되어 외래키 참조가 가능합니다.",
    "버전을 수정한 후 다시 저장하면 자동으로 재검증됩니다."
  ]
}
```

**사용자에게 표시:**

```
❌ 스키마 검증 실패

문제:
• products 테이블에 PRIMARY KEY가 설정되어 있지 않습니다.
• orders 테이블에서 products.id를 외래키로 참조하려고 하지만, products.id에 UNIQUE 제약조건이 없어 참조할 수 없습니다.

주의사항:
• 외래키는 반드시 부모 테이블의 PRIMARY KEY 또는 UNIQUE 컬럼을 참조해야 합니다.
• 모든 테이블에는 PRIMARY KEY를 설정하는 것이 좋습니다.

어떻게 수정하나요?
1. ERD에서 products 테이블의 id 컬럼에 PK(Primary Key) 체크박스를 활성화하세요.
2. products.id를 PRIMARY KEY로 설정하면 자동으로 UNIQUE 제약조건이 적용되어 외래키 참조가 가능합니다.
3. 버전을 수정한 후 다시 저장하면 자동으로 재검증됩니다.

[ERD 수정하기] 버튼
```

**사용자 수정 후 재검증:**

```sql
CREATE TABLE products (
    id BIGINT PRIMARY KEY,  -- ✅ PK 추가!
    name VARCHAR(200),
    price DECIMAL(10,2)
);

CREATE TABLE orders (
    id BIGINT PRIMARY KEY,
    product_id BIGINT,
    quantity INTEGER
);

ALTER TABLE orders
ADD CONSTRAINT fk_orders_products
FOREIGN KEY (product_id)
REFERENCES products (id);
```

**검증 성공:**

```
✅ 스키마 검증 성공

스키마 검증이 완료되었습니다. 문제가 없습니다.
이제 이 버전을 배포하거나 Mock Data를 생성할 수 있습니다.

[Mock Data 생성] [배포] 버튼
```

---

## 8. 결론

### 8.1 스키마 검증의 역할

1. **빌드 가능성 검증**: ERD가 실제 DB에서 동작하는지 확인
2. **조기 오류 발견**: 배포 전에 문제 발견 및 수정
3. **AI 기반 가이드**: 초보자도 이해할 수 있는 친절한 에러 설명

### 8.2 핵심 설계 원칙

1. **실제 DB 빌드**: 정적 검증이 아닌 실제 CREATE TABLE 실행
2. **Docker 테스트 DB**: 격리된 환경에서 안전하게 검증
3. **LLM 에러 분석**: 사용자 친화적인 설명 + 구체적인 수정 방법 제안
4. **DB 타입 자동 감지**: PostgreSQL/MySQL 자동 판별
5. **비동기 처리**: Kafka로 사용자 대기 시간 최소화

### 8.3 기대 효과

- 배포 전 오류 발견률: **95% 이상**
- 사용자 오류 이해도: **80% 향상** (LLM 설명 덕분)
- 수정 시간: **평균 5분 단축** (구체적인 제안 제공)
- 안정성: 실패한 스키마는 **Graph RAG에 저장 안 됨** (잘못된 패턴 학습 방지)

### 8.4 기술 스택 요약

| 컴포넌트 | 기술 | 역할 |
|---------|------|------|
| Schema 변환 | Python (SchemaConverter) | SchemaData → SQL DDL |
| DB 타입 감지 | LLM (GPT-4o) | PostgreSQL/MySQL 자동 판별 |
| 빌드 검증 | Docker PostgreSQL/MySQL | 실제 CREATE TABLE 실행 |
| 에러 분석 | LLM (GPT-4o, temp=0.3) | 친절한 설명 + 수정 제안 |
| 메시징 | Kafka | 비동기 검증 처리 |
| 결과 저장 | PostgreSQL (JSONB) | 검증 결과 영구 저장 |
