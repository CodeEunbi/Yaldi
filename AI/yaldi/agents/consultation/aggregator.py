"""
Response Aggregator

ì—¬ëŸ¬ Expert Agentì˜ ë‹µë³€ì„ í•˜ë‚˜ë¡œ í†µí•©
"""
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage
from typing import Dict, List
from config.settings import settings
import json
import logging
from utils.prompt_loader import prompt_loader
from utils.json_parser import parse_llm_json

logger = logging.getLogger(__name__)


class ResponseAggregator:
    """
    ë‹µë³€ í†µí•© Agent

    ì—­í• :
    - ì—¬ëŸ¬ Expert ë‹µë³€ì„ í•˜ë‚˜ì˜ ì¼ê´€ëœ ë‹µë³€ìœ¼ë¡œ í†µí•©
    - ìƒì¶©ë˜ëŠ” ì¡°ì–¸ì´ ìˆìœ¼ë©´ Trade-off ë¶„ì„
    - ìš°ì„ ìˆœìœ„ ì œì•ˆ
    """

    def __init__(self):
        self.llm = ChatOpenAI(
            base_url=settings.GMS_BASE_URL,
            api_key=settings.GMS_API_KEY,
            model=settings.OPENAI_MODEL,
            temperature=0.2
        )

    async def aggregate(
        self,
        user_question: str,
        agent_responses: Dict[str, Dict]
    ) -> Dict:
        """
        ë‹µë³€ í†µí•©

        Args:
            user_question: ì›ë˜ ì§ˆë¬¸
            agent_responses: {
                "NormalizationExpert": {...},
                "IndexStrategyExpert": {...}
            }

        Returns:
            {
                "message": "í†µí•©ëœ ìµœì¢… ë‹µë³€",
                "schema_modifications": [...],
                "confidence": 0.88,
                "agents_used": ["NormalizationExpert", ...],
                "warnings": [...]
            }
        """
        try:
            logger.info(f"[Aggregator] Aggregating {len(agent_responses)} responses")

            # ë‹¨ì¼ Agent ì‘ë‹µì´ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
            if len(agent_responses) == 1:
                result = self._format_single_response(user_question, agent_responses)
                # ë‚®ì€ í™•ì‹ ë„ë©´ ì§ˆë¬¸ ì¬êµ¬ì„± ì œì•ˆ
                if result["confidence"] < 0.5:
                    result = await self._suggest_question_refinement(user_question, result)
                return result

            # ë³µìˆ˜ Agent ì‘ë‹µ í†µí•©
            result = await self._aggregate_multiple(user_question, agent_responses)

            # ë‚®ì€ í™•ì‹ ë„ë©´ ì§ˆë¬¸ ì¬êµ¬ì„± ì œì•ˆ
            if result["confidence"] < 0.5:
                result = await self._suggest_question_refinement(user_question, result)

            return result

        except Exception as e:
            logger.error(f"[Aggregator] Error: {str(e)}", exc_info=True)
            raise

    def _format_single_response(
        self,
        user_question: str,
        agent_responses: Dict[str, Dict]
    ) -> Dict:
        """ë‹¨ì¼ Agent ì‘ë‹µ í¬ë§·"""
        agent_name, response = list(agent_responses.items())[0]

        message = response.get("answer", "")

        # optionsê°€ ìˆìœ¼ë©´ ì¶”ê°€
        options = response.get("options", [])
        if options:
            message += "\n\n### ì„ íƒ ê°€ëŠ¥í•œ ì˜µì…˜\n\n"
            for i, option in enumerate(options, 1):
                message += f"**ì˜µì…˜ {i}: {option.get('title', '')}**\n"
                if option.get('pros'):
                    message += f"- ì¥ì : {', '.join(option['pros'])}\n"
                if option.get('cons'):
                    message += f"- ë‹¨ì : {', '.join(option['cons'])}\n"
                if option.get('recommendation'):
                    message += f"- ì¶”ì²œ: {option['recommendation']}\n"
                message += "\n"

        return {
            "message": message,
            "schema_modifications": response.get("schema_modifications", []),
            "confidence": response.get("confidence", 0.5),
            "agents_used": [agent_name],
            "warnings": response.get("warnings", [])
        }

    async def _aggregate_multiple(
        self,
        user_question: str,
        agent_responses: Dict[str, Dict]
    ) -> Dict:
        """ë³µìˆ˜ Agent ì‘ë‹µ í†µí•©"""
        try:
            # System Prompt
            system_prompt = prompt_loader.load("consultation/aggregator_system")

            # Agent ë‹µë³€ë“¤ì„ í…ìŠ¤íŠ¸ë¡œ êµ¬ì„±
            responses_text = ""
            for agent_name, response in agent_responses.items():
                responses_text += f"\\n[{agent_name}]\\n"
                responses_text += f"ë‹µë³€: {response.get('answer', '')}\\n"
                responses_text += f"í™•ì‹ ë„: {response.get('confidence', 0)}\\n"
                if response.get('warnings'):
                    responses_text += f"ê²½ê³ : {', '.join(response['warnings'])}\\n"

            # User Prompt
            user_prompt_template = prompt_loader.load("consultation/aggregator_user")
            user_prompt = user_prompt_template.format(
                user_question=user_question,
                responses=responses_text
            )

            # LLM í˜¸ì¶œ
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=user_prompt)
            ]

            response = await self.llm.ainvoke(messages)
            result = parse_llm_json(response.content)

            # schema_modifications í†µí•©
            all_modifications = []
            for agent_response in agent_responses.values():
                all_modifications.extend(agent_response.get("schema_modifications", []))

            # ì¤‘ë³µ ì œê±° (ê°™ì€ action + table + column)
            unique_modifications = self._deduplicate_modifications(all_modifications)

            return {
                "message": result.get("message", ""),
                "schema_modifications": unique_modifications,
                "confidence": result.get("confidence", 0.5),
                "agents_used": list(agent_responses.keys()),
                "warnings": result.get("warnings", [])
            }

        except json.JSONDecodeError as e:
            logger.error(f"[Aggregator] JSON parsing error: {e}")
            # Fallback: ë‹¨ìˆœ ì—°ê²°
            return self._simple_concat(user_question, agent_responses)

    def _deduplicate_modifications(self, modifications: List[Dict]) -> List[Dict]:
        """ì¤‘ë³µ ìˆ˜ì •ì‚¬í•­ ì œê±°"""
        seen = set()
        unique = []

        for mod in modifications:
            key = (
                mod.get("action"),
                mod.get("details", {}).get("table"),
                mod.get("details", {}).get("column")
            )
            if key not in seen:
                seen.add(key)
                unique.append(mod)

        return unique

    def _simple_concat(
        self,
        user_question: str,
        agent_responses: Dict[str, Dict]
    ) -> Dict:
        """Fallback: ë‹¨ìˆœ ì—°ê²°"""
        message = ""
        for agent_name, response in agent_responses.items():
            message += f"\\n[{agent_name} ê´€ì ]\\n"
            message += response.get("answer", "") + "\\n"

        all_warnings = []
        for response in agent_responses.values():
            all_warnings.extend(response.get("warnings", []))

        return {
            "message": message,
            "schema_modifications": [],
            "confidence": 0.5,
            "agents_used": list(agent_responses.keys()),
            "warnings": list(set(all_warnings))
        }

    async def _suggest_question_refinement(
        self,
        user_question: str,
        current_result: Dict
    ) -> Dict:
        """
        ë‚®ì€ í™•ì‹ ë„ì¼ ë•Œ ì§ˆë¬¸ ì¬êµ¬ì„± ì œì•ˆ

        Meta Agent ì—­í• : ì§ˆë¬¸ì„ ë” ëª…í™•í•˜ê²Œ ë§Œë“¤ê¸° ìœ„í•œ ì œì•ˆ
        """
        try:
            logger.info("[Aggregator] Low confidence, suggesting question refinement")

            system_prompt = """ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ë¶ˆëª…í™•í•œ ì§ˆë¬¸ì„ ë” êµ¬ì²´ì ìœ¼ë¡œ ë§Œë“œëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤.

ì‚¬ìš©ì ì§ˆë¬¸ì´ ì• ë§¤í•˜ê±°ë‚˜ ë„ˆë¬´ ê´‘ë²”ìœ„í•  ë•Œ, ë‹¤ìŒê³¼ ê°™ì´ ë„ì™€ì£¼ì„¸ìš”:
1. ì§ˆë¬¸ì´ ì™œ ë¶ˆëª…í™•í•œì§€ ì„¤ëª…
2. êµ¬ì²´ì ì¸ ì§ˆë¬¸ ì˜ˆì‹œ 2-3ê°œ ì œì‹œ

JSON í˜•ì‹:
{
    "refined_suggestions": [
        "User í…Œì´ë¸” ì •ê·œí™” ë°©ë²•ì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?",
        "PK ì„ íƒ ê¸°ì¤€ì„ ì•Œê³  ì‹¶ìœ¼ì‹ ê°€ìš”?"
    ],
    "reason": "ì§ˆë¬¸ì´ ë„ˆë¬´ ê´‘ë²”ìœ„í•˜ì—¬ êµ¬ì²´ì ì¸ ë‹µë³€ì´ ì–´ë µìŠµë‹ˆë‹¤."
}"""

            user_prompt = f"""ì›ë˜ ì§ˆë¬¸: {user_question}

í˜„ì¬ ë‹µë³€: {current_result.get('message', '')}
í™•ì‹ ë„: {current_result.get('confidence', 0)}

ì´ ì§ˆë¬¸ì„ ë” êµ¬ì²´ì ìœ¼ë¡œ ë§Œë“¤ì–´ì£¼ì„¸ìš”."""

            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=user_prompt)
            ]

            response = await self.llm.ainvoke(messages)
            suggestions = parse_llm_json(response.content)

            # ê¸°ì¡´ ë‹µë³€ì— ì¬êµ¬ì„± ì œì•ˆ ì¶”ê°€
            refinement_text = f"\n\nğŸ’¡ **ì§ˆë¬¸ì„ ë” êµ¬ì²´ì ìœ¼ë¡œ ë°”ê¿”ë³´ì‹œê² ì–´ìš”?**\n\n"
            refinement_text += f"{suggestions.get('reason', '')}\n\n"
            refinement_text += "**ì¶”ì²œ ì§ˆë¬¸:**\n"
            for i, suggestion in enumerate(suggestions.get('refined_suggestions', []), 1):
                refinement_text += f"{i}. {suggestion}\n"

            current_result["message"] += refinement_text
            current_result["warnings"].append("ì§ˆë¬¸ì´ ë¶ˆëª…í™•í•˜ì—¬ ì¬êµ¬ì„± ì œì•ˆ í¬í•¨")

            return current_result

        except Exception as e:
            logger.error(f"[Aggregator] Question refinement error: {e}")
            # ì‹¤íŒ¨í•´ë„ ê¸°ì¡´ ê²°ê³¼ ë°˜í™˜
            return current_result
